# YOLOv13 Triple Input - Enhanced Object Detection

![License](https://img.shields.io/badge/license-AGPL--3.0-blue)
![Python](https://img.shields.io/badge/python-3.8%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-1.9%2B-red)
![Status](https://img.shields.io/badge/status-Production%20Ready-green)
![Variants](https://img.shields.io/badge/variants-n%2Fs%2Fm%2Fl%2Fx-purple)

A **production-ready** implementation of YOLOv13 with **triple image input** for enhanced object detection. Process 3 images simultaneously with attention-based fusion across **5 model variants** (nano to extra-large).

## ğŸŒŸ Key Features

- âœ… **Triple Input Processing**: Process 3 images with attention-based fusion
- âœ… **5 Model Variants**: YOLOv13n/s/m/l/x with different parameter scales  
- âœ… **Production Ready**: Complete training and inference pipeline
- âœ… **Memory Optimized**: Configurable batch sizes and model scaling

## ğŸ—ï¸ Architecture Overview

![YOLOv13l Architecture](./yolov13l_architecture.svg)

```
Input: [Primary Image, Detail Image 1, Detail Image 2]
        â†“
   TripleInputConv (Individual processing + Attention fusion)
        â†“
   Scalable YOLOv13 Backbone (variant-specific depth/width scaling)
        â†“ 
   Multi-scale Detection Head â†’ [P3, P4, P5] â†’ Results
```

### Model Variants

| Variant | Parameters | Use Case |
|---------|------------|----------|
| **YOLOv13n** | ~2.6M | Real-time, mobile, edge devices |
| **YOLOv13s** | ~9.0M | Balanced speed/accuracy |
| **YOLOv13m** | ~25M | High accuracy applications |
| **YOLOv13l** | ~45M | Maximum accuracy |
| **YOLOv13x** | ~68M | Research, highest accuracy |

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/yolo_3dual_input.git
cd yolo_3dual_input

# Install dependencies
pip install -r requirements.txt
```

### Basic Usage

#### 1. **Training with Model Variants**

```bash
# Train with small variant (recommended for most cases)
python train_triple.py --data working_dataset.yaml --model yolov13s --epochs 50 --batch 8 --device cpu

# Train with nano variant (fastest)
python train_triple.py --data working_dataset.yaml --model yolov13n --epochs 100 --batch 16 --device cpu

# Train with medium variant (higher accuracy)
python train_triple.py --data working_dataset.yaml --model yolov13m --epochs 50 --batch 4 --device cpu
```

#### 2. **Inference**

```bash
# Run inference with trained model
python triple_inference.py --weights runs/train/triple_yolo/weights/best.pt --source path/to/images
```

#### 3. **Complete Training Pipeline**

```bash
# All-in-one training with dataset preparation
python fix_and_train.py --train --epochs 50 --batch 8 --device cpu
```

## ğŸ“ Dataset Structure

```
training_data_demo/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/          # Primary training images  
â”‚   â””â”€â”€ val/            # Primary validation images
â””â”€â”€ labels/
    â”œâ”€â”€ train/          # YOLO format labels
    â””â”€â”€ val/            # YOLO format labels
```

### Label Format (Standard YOLO)
```
class_id center_x center_y width height
```

## ğŸ› ï¸ Advanced Usage

### Model Creation with Python API

```python
from ultralytics import YOLO

# Load different variants
model_n = YOLO('yolov13/ultralytics/cfg/models/v13/yolov13n.yaml')  # Nano
model_s = YOLO('yolov13/ultralytics/cfg/models/v13/yolov13s.yaml')  # Small  
model_m = YOLO('yolov13/ultralytics/cfg/models/v13/yolov13m.yaml')  # Medium
model_l = YOLO('yolov13/ultralytics/cfg/models/v13/yolov13l.yaml')  # Large
model_x = YOLO('yolov13/ultralytics/cfg/models/v13/yolov13x.yaml')  # Extra Large

# Train with custom settings
results = model_s.train(
    data='working_dataset.yaml',
    epochs=100,
    imgsz=640,
    batch=16
)
```

### Triple Input Inference

```python
from triple_inference import TripleYOLOInference

# Initialize inference engine
inference = TripleYOLOInference(
    model_path='runs/train/best.pt',
    device='cpu'
)

# Run inference on triple images
results = inference.predict(
    primary_image='path/to/primary.jpg',
    detail1_image='path/to/detail1.jpg', 
    detail2_image='path/to/detail2.jpg'
)
```

## ğŸ“Š Performance Benchmarks

### Inference Speed (CPU - Intel i9-9880H)

| Variant | Parameters | Inference Time | FPS | Memory Usage |
|---------|------------|----------------|-----|--------------|
| YOLOv13n | 2.6M | ~50ms | ~20 | ~1.5GB |
| YOLOv13s | 9.0M | ~75ms | ~13 | ~2.0GB |
| YOLOv13m | 25M | ~120ms | ~8 | ~3.0GB |
| YOLOv13l | 45M | ~180ms | ~6 | ~4.0GB |
| YOLOv13x | 68M | ~250ms | ~4 | ~5.0GB |

### Training Configuration Recommendations

| Use Case | Variant | Batch Size | Epochs | Device |
|----------|---------|------------|---------|---------|
| **Development/Testing** | yolov13n | 16 | 50 | CPU |
| **Production Balance** | yolov13s | 8 | 100 | CPU/GPU |
| **High Accuracy** | yolov13m | 4 | 150 | GPU |
| **Maximum Performance** | yolov13l/x | 2 | 200 | GPU |

## ğŸ¯ Model Selection Guide

### Choose Your Variant

| Use Case | Recommended Variant | Reasoning |
|----------|-------------------|-----------|
| **Real-time applications** | YOLOv13n | Fastest inference, lowest memory |
| **Mobile deployment** | YOLOv13n/s | Small size, efficient |
| **General purpose** | YOLOv13s | Good balance speed/accuracy |
| **High accuracy needed** | YOLOv13m/l | Better detection performance |
| **Research/benchmarking** | YOLOv13x | Maximum accuracy |

## ğŸ”§ Configuration Files

### Model Configurations
- `yolov13/ultralytics/cfg/models/v13/yolov13n.yaml` - Nano variant
- `yolov13/ultralytics/cfg/models/v13/yolov13s.yaml` - Small variant  
- `yolov13/ultralytics/cfg/models/v13/yolov13m.yaml` - Medium variant
- `yolov13/ultralytics/cfg/models/v13/yolov13l.yaml` - Large variant
- `yolov13/ultralytics/cfg/models/v13/yolov13x.yaml` - Extra Large variant

### Dataset Configuration
- `working_dataset.yaml` - Main dataset configuration
- `triple_dataset.yaml` - Triple input dataset configuration

## ğŸ§ª Testing & Validation

### Run Tests

```bash
# Test model loading for all variants
python -c "
from ultralytics import YOLO
variants = ['n', 's', 'm', 'l', 'x']
for v in variants:
    model = YOLO(f'yolov13/ultralytics/cfg/models/v13/yolov13{v}.yaml')
    print(f'âœ… YOLOv13{v} loaded successfully')
"

# Test training pipeline
python fix_and_train.py --train --epochs 3 --batch 1 --device cpu
```

## ğŸ“‹ Project Structure

```
yolo_3dual_input/
â”œâ”€â”€ yolov13/                    # Core YOLOv13 implementation
â”‚   â””â”€â”€ ultralytics/
â”‚       â””â”€â”€ cfg/models/v13/     # Model variant configurations
â”œâ”€â”€ training_data_demo/         # Sample dataset
â”œâ”€â”€ runs/                       # Training outputs
â”œâ”€â”€ deployment_package/         # Standalone deployment
â”œâ”€â”€ train_triple.py            # Main training script
â”œâ”€â”€ fix_and_train.py           # Complete training pipeline
â”œâ”€â”€ triple_inference.py        # Inference script
â”œâ”€â”€ detect_triple.py           # Detection script
â””â”€â”€ working_dataset.yaml       # Dataset configuration
```

## ğŸš€ Deployment

### Standalone Deployment Package

```bash
# Use the pre-built deployment package
cd deployment_package
python setup_deployment.py
python train_triple.py --data triple_dataset.yaml --model yolov13s --epochs 50
```

The `deployment_package/` contains everything needed to run on any machine:
- Complete YOLOv13 implementation
- All model variants
- Sample training data
- Requirements and setup scripts

## ğŸ¤ Contributing

### Development Setup

```bash
# Fork and clone
git clone https://github.com/yourusername/yolo_3dual_input.git
cd yolo_3dual_input

# Install development dependencies
pip install -r requirements.txt

# Run tests
python examples/basic_usage.py
```

## ğŸ“„ License

This project is licensed under the AGPL-3.0 License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **YOLOv13**: Based on the original YOLOv13 architecture
- **Ultralytics**: For the excellent YOLO framework foundation
- **PyTorch**: For the deep learning framework

## ğŸ“ Support

- **ğŸ› Bug Reports**: [Create Issue](https://github.com/yourusername/yolo_3dual_input/issues/new)
- **ğŸ’¡ Feature Requests**: [GitHub Discussions](https://github.com/yourusername/yolo_3dual_input/discussions)
- **ğŸ“š Documentation**: [Project Wiki](https://github.com/yourusername/yolo_3dual_input/wiki)

## ğŸ—ºï¸ Roadmap

### Current Version (v1.0)
- âœ… Complete YOLOv13 variants (n/s/m/l/x)
- âœ… Triple input processing
- âœ… Production-ready training pipeline
- âœ… Comprehensive documentation

### Future Versions
- [ ] ONNX export support
- [ ] TensorRT optimization
- [ ] Web interface demo
- [ ] Mobile deployment guides

---

## ğŸš€ Get Started Now!

```bash
# One-command quick test
git clone https://github.com/yourusername/yolo_3dual_input.git && \
cd yolo_3dual_input && \
python train_triple.py --data working_dataset.yaml --model yolov13s --epochs 3 --batch 1 --device cpu
```

**ğŸŒŸ Star this repository if you find it useful!**

---

*YOLOv13 Triple Input - Production Ready Object Detection with Multiple Model Variants*